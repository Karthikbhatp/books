{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Java concurrency in practice\n",
    "## Chapter - 5\n",
    "## Building Blocks \n",
    "\n",
    "* [5.1 Synchronized collections](#1)\n",
    "* [5.2 Concurrent collections](#2)\n",
    "* [5.3 Blocking queues and the producer-consumer pattern](#5.3-Blocking-queues-and-the-producer-consumer-pattern)\n",
    "* [5.4 Blocking and interruptible methods](#5.4-Blocking-and-interruptible-methods)\n",
    "* [5.5 Synchronizers](#5.5-Synchronizers)\n",
    "* [5.5 Synchronizers](#5.5-synchronizers)\n",
    "* [5.5 Synchronizers](#5.5_synchronizers)\n",
    "* [5.6 Building an efficient,scalable result cache](#5.6-Building-an-efficient,scalable-result-cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter covers the most useful concurrent building blocks, especially those introduced in Java 5.0 and Java 6, and some patterns for using them to structure concurrent applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Synchronized collections<a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synchronized collection classes include Vector and Hashtable, part of the orig- inal JDK, as well as their cousins added in JDK 1.2, the synchronized wrapper classes created by the Collections.synchronizedXxx factory methods. These classes achieve thread safety by encapsulating their state and synchronizing every public method so that only one thread at a time can access the collection state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems with synchronized collections\n",
    "The synchronized collections are thread-safe, but you may sometimes need to use additional client-side locking to guard compound actions.\n",
    "With a synchronized collection, compound actions are still technically thread-safe even without client-side locking, but they may not behave as you might expect when other threads can concurrently modify the collection.\n",
    "\n",
    "Two methods that operate on a Vector, getLast and delete- Last, both of which are check-then-act sequences. Each calls size to determine the size of the array and uses the resulting value to retrieve or remove the last\n",
    "element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * UnsafeVectorHelpers\n",
    " * <p/>\n",
    " * Compound actions on a Vector that may produce confusing results\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class UnsafeVectorHelpers {\n",
    "    public static Object getLast(Vector list) {\n",
    "        int lastIndex = list.size() - 1;\n",
    "        return list.get(lastIndex);\n",
    "    }\n",
    "\n",
    "    public static void deleteLast(Vector list) {\n",
    "        int lastIndex = list.size() - 1;\n",
    "        list.remove(lastIndex);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods seem harmless, and in a sense they are—they can’t corrupt the Vector, no matter how many threads call them simultaneously. But the caller of these methods might have a different opinion. If thread A calls getLast on a Vector with ten elements, thread B calls deleteLast on the same Vector, and the operations are interleaved, getLast throws ```ArrayIndexOutOfBoundsException```\n",
    "\n",
    "Between the call to size and the subsequent call to get in getLast, the Vector shrank and the index computed in the first step is no longer valid. This is perfectly consistent with the specification of Vector—it throws an exception if asked for a nonexistent element. But this is not what a caller expects getLast to do, even in the face of concurrent modification, unless perhaps the Vector was empty to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * SafeVectorHelpers\n",
    " * <p/>\n",
    " * Compound actions on Vector using client-side locking\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class SafeVectorHelpers {\n",
    "    public static Object getLast(Vector list) {\n",
    "        synchronized (list) {\n",
    "            int lastIndex = list.size() - 1;\n",
    "            return list.get(lastIndex);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public static void deleteLast(Vector list) {\n",
    "        synchronized (list) {\n",
    "            int lastIndex = list.size() - 1;\n",
    "            list.remove(lastIndex);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterators and ConcurrentModificationException\n",
    "The standard way to iterate a Collection is with an Iterator, either explicitly or through the for-each loop syntax introduced in Java 5.0, but using iterators does not obviate the need to lock the collection during iteration if other threads can concurrently modify it. The iterators returned by the synchronized collections are not designed to deal with concurrent modification, and they are fail-fast—meaning that if they detect that the collection has changed since iteration began, they throw the unchecked ConcurrentModificationException.\n",
    "\n",
    "These fail-fast iterators are not designed to be foolproof—they are designed to catch concurrency errors on a “good-faith-effort” basis and thus act only as early-warning indicators for concurrency problems. They are implemented by associating a modification count with the collection: if the modification count changes during iteration, hasNext or next throws ConcurrentModificationEx- ception. However, this check is done without synchronization, so there is a risk of seeing a stale value of the modification count and therefore that the iterator does not realize a modification has been made. This was a deliberate design tradeoff to reduce the performance impact of the concurrent modification detection code.\n",
    "\n",
    "There are several reasons, however, why locking a collection during iteration may be undesirable. Other threads that need to access the collection will block until the iteration is complete; if the collection is large or the task performed for each element is lengthy, they could wait a long time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden iterators\n",
    "The addTenThings method could throw ConcurrentModificationException, because the collection is being iterated by toString in the process of preparing the debugging message. Of course, the real problem is that HiddenIterator is not thread-safe; the HiddenIterator lock should be acquired before using set in the println call, but debugging and logging code commonly neglect to do this.\n",
    "The real lesson here is that the greater the distance between the state and the synchronization that guards it, the more likely that someone will forget to use proper synchronization when accessing that state. If HiddenIterator wrapped the HashSet with a synchronizedSet, encapsulating the synchronization, this sort of error would not occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.lang.annotation.ElementType;\n",
    "import java.lang.annotation.Retention;\n",
    "import java.lang.annotation.RetentionPolicy;\n",
    "import java.lang.annotation.Target;\n",
    "import java.lang.annotation.*;\n",
    "\n",
    "@Target({ElementType.FIELD, ElementType.METHOD})\n",
    "@Retention(RetentionPolicy.RUNTIME)\n",
    "public @interface GuardedBy {\n",
    "    String value();\n",
    "}\n",
    "\n",
    "/**\n",
    " * HiddenIterator\n",
    " * <p/>\n",
    " * Iteration hidden within string concatenation\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class HiddenIterator {\n",
    "    @GuardedBy(\"this\") \n",
    "    private final Set<Integer> set = new HashSet<Integer>();\n",
    "\n",
    "    public synchronized void add(Integer i) {\n",
    "        set.add(i);\n",
    "    }\n",
    "\n",
    "    public synchronized void remove(Integer i) {\n",
    "        set.remove(i);\n",
    "    }\n",
    "\n",
    "    public void addTenThings() {\n",
    "        Random r = new Random();\n",
    "        for (int i = 0; i < 10; i++)\n",
    "            add(r.nextInt());\n",
    "        System.out.println(\"DEBUG: added ten elements to \" + set);// Hidden iteration\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration is also indirectly invoked by the collection’s hashCode and equals methods, which may be called if the collection is used as an element or key of another collection. Similarly, the containsAll, removeAll, and retainAll meth- ods, as well as the constructors that take collections as arguments, also iterate the collection. All of these indirect uses of iteration can cause ConcurrentModifica- tionException.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Concurrent collections<a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concurrent collections are designed for concurrent ac- cess from multiple threads. Java 5.0 adds __ConcurrentHashMap__, a replacement for synchronized hash-based Map implementations, and __CopyOnWriteArrayList__, a replacement for synchronized List implementations for cases where traversal is the dominant operation. The new ConcurrentMap interface adds support for common compound actions such as put-if-absent, replace, and conditional remove.\n",
    "\n",
    "Replacing synchronized collections with concurrent collections can offer dramatic scalability improvements with little risk.\n",
    "Java 5.0 also adds two new collection types, __Queue__ and __BlockingQueue__. A Queue is intended to hold a set of elements temporarily while they await process- ing. Several implementations are provided, including ConcurrentLinkedQueue, a traditional FIFO queue, and __PriorityQueue__, a (non concurrent) priority ordered queue. \n",
    "\n",
    "BlockingQueue extends Queue to add blocking insertion and retrieval operations. If the queue is empty, a retrieval blocks until an element is available, and if the queue is full (for bounded queues) an insertion blocks until there is space available. Blocking queues are extremely useful in producer-consumer designs, and are covered in greater detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConcurrentHashMap\n",
    "ConcurrentHashMap is a hash-based Map like HashMap, but it uses an entirely different locking strategy that offers better concurrency and scalability. Instead of synchronizing every method on a common lock, restricting access to a single thread at a time, it uses a finer-grained locking mechanism called lock __striping__ to allow a greater degree of shared access. Arbitrarily many reading threads can access the map concurrently, readers can access the map concurrently with writers, and a limited number of writers can modify the map concurrently. The result is far higher throughput under concurrent access, with little performance penalty for single-threaded access.\n",
    "\n",
    "ConcurrentHashMap, along with the other concurrent collections, further improve on the synchronized collection classes by providing iterators that do not throw ConcurrentModificationException, thus eliminating the need to lock the collection during iteration. The iterators returned by ConcurrentHashMap are weakly consistent instead of fail-fast. A weakly consistent iterator can tolerate con- current modification, traverses elements as they existed when the iterator was constructed, and may (but is not guaranteed to) reflect modifications to the col- lection after the construction of the iterator.\n",
    "\n",
    "__size__ is allowed to return an approximation instead of an exact count. While at first this may seem disturbing, in reality methods like size and isEmpty are far less useful in concurrent environments because these quantities are moving targets.\n",
    "\n",
    "This might be necessary in unusual cases such as adding sev- eral mappings atomically, or iterating the Map several times and needing to see the same elements in the same order. On the whole, though, this is a reason- able tradeoff: concurrent collections should be expected to change their contents continuously.\n",
    "\n",
    "Only if your application needs to lock the map for exclusive access is ConcurrentHashMap not an appropriate drop-in replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CopyOnWriteArrayList\n",
    "__CopyOnWriteArrayList__ is a concurrent replacement for a synchronized List that offers better concurrency in some common situations and eliminates the need to lock or copy the collection during iteration. (Similarly, __CopyOnWriteArraySet__ is a concurrent replacement for a synchronized Set.)\n",
    "\n",
    "They implement mutability by creating and republishing a new copy of the collection every time it is modified. Iterators for the copy-on-write collections retain a reference to the backing array that was current at the start of iteration, and since this will never change, they need to synchronize only briefly to ensure visibility of the array contents. As a result, multiple threads can iterate the collection without interference from one another or from threads wanting to modify the collection. The iterators returned by the copy-on-write collections __do not throw ConcurrentModificationException__ and return the elements exactly as they were at the time the iterator was created, regardless of subsequent modifications.\n",
    "\n",
    "Obviously, there is some cost to copying the backing array every time the collection is modified, especially if the collection is large; __the copy-on-write collections are reasonable to use only when iteration is far more common than modification.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Blocking queues and the producer-consumer pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blocking queues provide blocking put and take methods as well as the timed equivalents offer and poll. If the queue is full, put blocks until space becomes available; if the queue is empty, take blocks until an element is available. Queues can be bounded or unbounded; unbounded queues are never full, so a put on an unbounded queue never blocks.\n",
    "Blocking queues support the producer-consumer design pattern. A producer- consumer design separates the identification of work to be done from the exe- cution of that work by placing work items on a “to do” list for later processing, rather than processing them immediately as they are identified. The producer- consumer pattern simplifies development because it removes code dependencies between producer and consumer classes, and simplifies workload management by decoupling activities that may produce or consume data at different or vari- able rates.\n",
    "\n",
    "In a producer-consumer design built around a blocking queue, producers place data onto the queue as it becomes available, and consumers retrieve data from the queue when they are ready to take the appropriate action. Producers don’t need to know anything about the identity or number of consumers, or even whether they are the only producer—all they have to do is place data items on the queue. Similarly, consumers need not know who the producers are or where the work came from. BlockingQueue simplifies the implementation of producer- consumer designs with any number of producers and consumers.\n",
    "\n",
    "The familiar division of labor for two people washing the dishes is an example of a producer-consumer design: one person washes the dishes and places them in the dish rack, and the other person retrieves the dishes from the rack and dries them. In this scenario, the dish rack acts as a blocking queue; if there are no dishes in the rack, the consumer waits until there are dishes to dry, and if the rack fills up, the producer has to stop washing until there is more space.\n",
    "\n",
    "Blocking queues simplify the coding of consumers, since take blocks until data is available. If the producers don’t generate work fast enough to keep the consumers busy, the consumers just wait until more work is available. Sometimes this is perfectly acceptable (as in a server application when no client is requesting service), and sometimes it indicates that the ratio of producer threads to consumer threads should be adjusted to achieve better utilization (as in a web crawler or other application in which there is effectively infinite work to do).\n",
    "\n",
    "If the producers consistently generate work faster than the consumers can process it, eventually the application will run out of memory because work items will queue up without bound. Again, the blocking nature of put greatly simplifies coding of producers; if we use a bounded queue, then when the queue fills up the producers block, giving the consumers time to catch up because a blocked producer cannot generate more work.\n",
    "\n",
    "Blocking queues also provide an offer method, which returns a failure status if the item cannot be enqueued. This enables you to create more flexible policies for dealing with overload, such as shedding load, serializing excess work items and writing them to disk, reducing the number of producer threads, or throttling producers in some other manner.\n",
    "\n",
    "It is tempting to assume that the consumers will always keep up, so that you need not place any bounds on the size of work queues, but this is a prescription for rearchitecting your system later. Build resource management into your design early using blocking queues—it is a lot easier to do this up front than to retrofit it later. \n",
    "\n",
    "PriorityBlockingQueue is a priority-ordered queue, which is useful when you want to process elements in an order other than FIFO. Just like other sorted collections, PriorityBlockingQueue can compare elements according to their natural order (if they implement Comparable) or using a Comparator.\n",
    "\n",
    "The last BlockingQueue implementation, SynchronousQueue, is not really a queue at all, in that it maintains no storage space for queued elements. Instead, it maintains a list of queued threads waiting to enqueue or dequeue an element. In the dish-washing analogy, this would be like having no dish rack, but instead handing the washed dishes directly to the next available dryer. While this may seem a strange way to implement a queue, it reduces the latency associated with moving data from producer to consumer because the work can be handed off directly. (In a traditional queue, the enqueue and dequeue operations must com- plete sequentially before a unit of work can be handed off.) The direct handoff also feeds back more information about the state of the task to the producer; when the handoff is accepted, it knows a consumer has taken responsibility for it, rather than simply letting it sit on a queue somewhere—much like the difference between handing a document to a colleague and merely putting it in her mailbox and hoping she gets it soon.\n",
    "\n",
    "Synchronous queues are generally suitable only when there are enough consumers that there nearly always will be one ready to take the handoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: desktop search\n",
    "Windows Indexing service. DiskCrawler shows a producer task that searches a file hierarchy for files meeting an indexing criterion and puts their names on the work queue; Indexer shows the consumer task that takes file names from the queue and indexes them.\n",
    "\n",
    "Each of the activities has only a single task to do, and the blocking queue handles all the flow control, so the code for each is simpler and clearer.\n",
    "\n",
    "Producers and consumers can execute concurrently; if one is I/O-bound and the other is CPU-bound, executing them concurrently yields better overall through- put than executing them sequentially. If the producer and consumer activities are parallelizable to different degrees, tightly coupling them reduces parallelizability to that of the less parallelizable activity.\n",
    "\n",
    "Listing startIndexing starts several crawlers and indexers, each in their own thread. As written, the consumer threads never exit, which prevents the program from termi- nating; we examine several techniques for addressing this problem in Chapter 7. While this example uses explicitly managed threads, many producer-consumer designs can be expressed using the Executor task execution framework, which itself uses the producer-consumer pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File;\n",
    "import java.io.FileFilter;\n",
    "import java.util.concurrent.*;\n",
    "\n",
    "/**\n",
    " * ProducerConsumer\n",
    " * <p/>\n",
    " * Producer and consumer tasks in a desktop search application\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class ProducerConsumer {\n",
    "    static class FileCrawler implements Runnable {\n",
    "        private final BlockingQueue<File> fileQueue;\n",
    "        private final FileFilter fileFilter;\n",
    "        private final File root;\n",
    "\n",
    "        public FileCrawler(BlockingQueue<File> fileQueue,\n",
    "                           final FileFilter fileFilter,\n",
    "                           File root) {\n",
    "            this.fileQueue = fileQueue;\n",
    "            this.root = root;\n",
    "            this.fileFilter = new FileFilter() {\n",
    "                public boolean accept(File f) {\n",
    "                    return f.isDirectory() || fileFilter.accept(f);\n",
    "                }\n",
    "            };\n",
    "        }\n",
    "\n",
    "        private boolean alreadyIndexed(File f) {\n",
    "            return false;\n",
    "        }\n",
    "\n",
    "        public void run() {\n",
    "            try {\n",
    "                crawl(root);\n",
    "            } catch (InterruptedException e) {\n",
    "                Thread.currentThread().interrupt();\n",
    "            }\n",
    "        }\n",
    "\n",
    "        private void crawl(File root) throws InterruptedException {\n",
    "            File[] entries = root.listFiles(fileFilter);\n",
    "            if (entries != null) {\n",
    "                for (File entry : entries)\n",
    "                    if (entry.isDirectory())\n",
    "                        crawl(entry);\n",
    "                    else if (!alreadyIndexed(entry))\n",
    "                        fileQueue.put(entry);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "static class Indexer implements Runnable {\n",
    "    private final BlockingQueue<File> queue;\n",
    "\n",
    "    public Indexer(BlockingQueue<File> queue) {\n",
    "        this.queue = queue;\n",
    "    }\n",
    "\n",
    "    public void run() {\n",
    "        try {\n",
    "            while (true)\n",
    "                indexFile(queue.take());\n",
    "        } catch (InterruptedException e) {\n",
    "            Thread.currentThread().interrupt();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public void indexFile(File file) {\n",
    "        // Index the file...\n",
    "    };\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "private static final int BOUND = 10;\n",
    "private static final int N_CONSUMERS = Runtime.getRuntime().availableProcessors();\n",
    "\n",
    "public static void startIndexing(File[] roots) {\n",
    "    BlockingQueue<File> queue = new LinkedBlockingQueue<File>(BOUND);\n",
    "    FileFilter filter = new FileFilter() {\n",
    "        public boolean accept(File file) {\n",
    "            return true;\n",
    "        }\n",
    "    };\n",
    "\n",
    "    for (File root : roots)\n",
    "        new Thread(new FileCrawler(queue, filter, root)).start();\n",
    "\n",
    "    for (int i = 0; i < N_CONSUMERS; i++)\n",
    "        new Thread(new Indexer(queue)).start();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deques and work stealing\n",
    "Java 6 also adds another two collection types, Deque (pronounced “deck”) and BlockingDeque, that extend Queue and BlockingQueue. A Deque is a double ended queue that allows efficient insertion and removal from both the head and the tail. Implementations include ArrayDeque and LinkedBlockingDeque.\n",
    "\n",
    "Just as blocking queues lend themselves to the producer-consumer pattern, deques lend themselves to a related pattern called work stealing. A producer-consumer design has one shared work queue for all consumers; in a work stealing design, every consumer has its own deque. If a consumer exhausts the work in its own deque, it can steal work from the tail of someone else’s deque. Work stealing can be more scalable than a traditional producer-consumer design because workers don’t contend for a shared work queue; most of the time they access only their own deque, reducing contention. When a worker has to access another’s queue, it does so from the tail rather than the head, further reducing contention.\n",
    "\n",
    "Work stealing is well suited to problems in which consumers are also producers—when performing a unit of work is likely to result in the identification of more work. For example, processing a page in a web crawler usually results in the identification of new pages to be crawled. Similarly, many graph-exploring algorithms, such as marking the heap during garbage collection, can be efficiently parallelized using work stealing. When a worker identifies a new unit of work, it places it at the end of its own deque (or alternatively, in a work sharing design, on that of another worker); when its deque is empty, it looks for work at the end of someone else’s deque, ensuring that each worker stays busy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Blocking and interruptible methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interruption is a cooperative mechanism. One thread cannot force another to stop what it is doing and do something else; when thread A interrupts thread B, A is merely requesting that B stop what it is doing when it gets to a convenient stop-ping point—if it feels like it.\n",
    "\n",
    "Blocking methods that are responsive to interruption make it easier to cancel long-running activities on a timely basis.\n",
    "When your code calls a method that throws InterruptedException, then your method is a blocking method too, and must have a plan for responding to inter- ruption. For library code, there are basically two choices:\n",
    "* Propagate the InterruptedException. This is often the most sensible policy if you can get away with it—just propagate the InterruptedException to your caller. This could involve not catching InterruptedException, or catching it and throwing it again after performing some brief activity-specific cleanup.\n",
    "* Restore the interrupt. Sometimes you cannot throw InterruptedException, for instance when your code is part of a Runnable. In these situations, you must catch InterruptedException and restore the interrupted status by calling interrupt on the current thread, so that code higher up the call stack can see that an interrupt was issued, as demonstrated in Listing 5.10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task{\n",
    "}\n",
    "public class TaskRunnable implements Runnable { \n",
    "    BlockingQueue<Task> queue;\n",
    "    public void run() {\n",
    "        try { \n",
    "            processTask(queue.take());\n",
    "        } catch (InterruptedException e) {\n",
    "            // restore interrupted status\n",
    "            Thread.currentThread().interrupt(); \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Synchronizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A synchronizer is any object that coordinates the control flow of threads based on its state. Blocking queues can act as synchronizers; other types of synchroniz- ers include semaphores, barriers, and latches. There are a number of synchronizer classes in the platform library; if these do not meet your needs, you can also create your own using the mechanisms described in Chapter 14.\n",
    "All synchronizers share certain structural properties: they encapsulate state that determines whether threads arriving at the synchronizer should be allowed to pass or forced to wait, provide methods to manipulate that state, and provide methods to wait efficiently for the synchronizer to enter the desired state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latches\n",
    "A latch is a synchronizer that can delay the progress of threads until it reaches its terminal state. A latch acts as a gate: until the latch reaches the terminal state the gate is closed and no thread can pass, and in the terminal state the gate opens, allowing all threads to pass. Once the latch reaches the terminal state, it cannot change state again, so it remains open forever. Latches can be used to ensure that certain activities do not proceed until other one-time activities complete, such as:\n",
    "* Ensuring that a computation does not proceed until resources it needs have been initialized.\n",
    "* Ensuring that a service does not start until other services on which it de- pends have started\n",
    "* Waiting until all the parties involved in an activity, for instance the players in a multi-player game, are ready to proceed\n",
    "\n",
    "CountDownLatch is a flexible latch implementation that can be used in any of these situations; it allows one or more threads to wait for a set of events to occur. The latch state consists of a counter initialized to a positive number, representing the number of events to wait for. The countDown method decrements the counter, indicating that an event has occurred, and the await methods wait for the counter to reach zero, which happens when all the events have occurred. If the counter is nonzero on entry, await blocks until the counter reaches zero, the waiting thread is interrupted, or the wait times out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class TestHarness {\n",
    "    public long timeTasks(int nThreads, final Runnable task)\n",
    "            throws InterruptedException {\n",
    "        final CountDownLatch startGate = new CountDownLatch(1);\n",
    "        final CountDownLatch endGate = new CountDownLatch(nThreads);\n",
    "\n",
    "        for (int i = 0; i < nThreads; i++) {\n",
    "            Thread t = new Thread() {\n",
    "                public void run() {\n",
    "                    try {\n",
    "                        startGate.await();\n",
    "                        try {\n",
    "                            task.run();\n",
    "                        } finally {\n",
    "                            endGate.countDown();\n",
    "                        }\n",
    "                    } catch (InterruptedException ignored) {\n",
    "                    }\n",
    "                }\n",
    "            };\n",
    "            t.start();\n",
    "        }\n",
    "\n",
    "        long start = System.nanoTime();\n",
    "        startGate.countDown();\n",
    "        endGate.await();\n",
    "        long end = System.nanoTime();\n",
    "        return end - start;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside runnable\n",
      "Inside runnable\n",
      "Inside runnable\n",
      "Inside runnable\n",
      "Inside runnable\n",
      "6764180\n"
     ]
    }
   ],
   "source": [
    "Runnable runnable  = () -> {\n",
    "\tSystem.out.println(\"Inside runnable\");\n",
    "};\n",
    "\n",
    "TestHarness harness = new TestHarness();\n",
    "long timeTasks = harness.timeTasks(5, runnable);\n",
    "System.out.println(timeTasks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FutureTask\n",
    "A computation rep- resented by a FutureTask is implemented with a Callable, the result-bearing equivalent of Runnable, and can be in one of three states: waiting to run, running, or completed. Completion subsumes all the ways a computation can complete, including normal completion, cancellation, and exception. Once a FutureTask enters the completed state, it stays in that state forever.\n",
    "The behavior of Future.get depends on the state of the task. If it is completed, get returns the result immediately, and otherwise blocks until the task transitions to the completed state and then returns the result or throws an exception. Fut- ureTask conveys the result from the thread executing the computation to the thread(s) retrieving the result; the specification of FutureTask guarantees that this transfer constitutes a safe publication of the result.\n",
    "\n",
    "FutureTask is used by the Executor framework to represent asynchronous tasks, and can also be used to represent any potentially lengthy computation that can be started before the results are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoadException extends Exception { }\n",
    "/**\n",
    " * StaticUtilities\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "class LaunderThrowable {\n",
    "\n",
    "    /**\n",
    "     * Coerce an unchecked Throwable to a RuntimeException\n",
    "     * <p/>\n",
    "     * If the Throwable is an Error, throw it; if it is a\n",
    "     * RuntimeException return it, otherwise throw IllegalStateException\n",
    "     */\n",
    "    public static RuntimeException launderThrowable(Throwable t) {\n",
    "        if (t instanceof RuntimeException)\n",
    "            return (RuntimeException) t;\n",
    "        else if (t instanceof Error)\n",
    "            throw (Error) t;\n",
    "        else\n",
    "            throw new IllegalStateException(\"Not unchecked\", t);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Preloader\n",
    " *\n",
    " * Using FutureTask to preload data that is needed later\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "interface ProductInfo {\n",
    "    public String getProductStock();\n",
    "}\n",
    "\n",
    "class SilverProductInfo implements ProductInfo{\n",
    "    String name = \"Silver\";\n",
    "    String stockPrice = null;\n",
    "    @Override\n",
    "    public String getProductStock() {\n",
    "        try {\n",
    "            Thread.sleep(1000);\n",
    "        } catch (InterruptedException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "        stockPrice = \"Stock Price: 10\";\n",
    "        return \"Stock Price: 10\";\n",
    "    }\n",
    "    @Override\n",
    "    public String toString() {\n",
    "        return \"SilverProductInfo [name=\" + name + \", stockPrice=\" + stockPrice + \"]\";\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class Preloader {\n",
    "    ProductInfo loadProductInfo() throws DataLoadException {\n",
    "        ProductInfo productInfo = new SilverProductInfo();\n",
    "        productInfo.getProductStock();\n",
    "        return productInfo;\n",
    "    }\n",
    "\n",
    "    private final FutureTask<ProductInfo> future =\n",
    "        new FutureTask<ProductInfo>(new Callable<ProductInfo>() {\n",
    "            public ProductInfo call() throws DataLoadException {\n",
    "                return loadProductInfo();\n",
    "            }\n",
    "        });\n",
    "    private final Thread thread = new Thread(future);\n",
    "\n",
    "    public void start() { thread.start(); }\n",
    "\n",
    "    public ProductInfo get()\n",
    "            throws DataLoadException, InterruptedException {\n",
    "        try {\n",
    "            return future.get();\n",
    "        } catch (ExecutionException e) {\n",
    "            Throwable cause = e.getCause();\n",
    "            if (cause instanceof DataLoadException)\n",
    "                throw (DataLoadException) cause;\n",
    "            else\n",
    "                throw LaunderThrowable.launderThrowable(cause);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SilverProductInfo [name=Silver, stockPrice=Stock Price: 10]\n"
     ]
    }
   ],
   "source": [
    "Preloader preloader = new Preloader();\n",
    "preloader.start();\n",
    "ProductInfo productInfo = preloader.get();\n",
    "System.out.println(productInfo);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When get throws an ExecutionException in Preloader, the cause will fall into one of three categories: a checked exception thrown by the Callable, a Run- timeException, or an Error. We must handle each of these cases separately, but we will use the launderThrowable utility method in Listing to encapsulate some of the messier exception-handling logic. Before calling launderThrowable, Preloader tests for the known checked exceptions and rethrows them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semaphores\n",
    "Counting semaphores are used to control the number of activities that can access a certain resource or perform a given action at the same time. Counting semaphores can be used to implement resource pools or to impose a bound on a collection.\n",
    "\n",
    "A Semaphore manages a set of virtual permits; the initial number of permits is passed to the Semaphore constructor. Activities can acquire permits (as long as some remain) and release permits when they are done with them. If no permit is available, acquire blocks until one is (or until interrupted or the operation times The release method returns a permit to the semaphore.\n",
    "\n",
    "A degenerate case of a counting semaphore is a binary semaphore, a Semaphore with an initial count of one. A binary semaphore can be used as a mutex with nonreentrant locking semantics; whoever holds the sole permit holds the mutex.\n",
    "\n",
    "Similarly, you can use a Semaphore to turn any collection into a block- ing bounded collection, as illustrated by BoundedHashSet in Listing. The semaphore is initialized to the desired maximum size of the collection. The add operation acquires a permit before adding the item into the underlying collec- tion. If the underlying add operation does not actually add anything, it releases the permit immediately. Similarly, a successful remove operation releases a per- mit, enabling more elements to be added. The underlying Set implementation knows nothing about the bound; this is handled by BoundedHashSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * BoundedHashSet\n",
    " * <p/>\n",
    " * Using Semaphore to bound a collection\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class BoundedHashSet <T> {\n",
    "    private final Set<T> set;\n",
    "    private final Semaphore sem;\n",
    "\n",
    "    public BoundedHashSet(int bound) {\n",
    "        this.set = Collections.synchronizedSet(new HashSet<T>());\n",
    "        sem = new Semaphore(bound);\n",
    "    }\n",
    "\n",
    "    public boolean add(T o) throws InterruptedException {\n",
    "        sem.acquire();\n",
    "        boolean wasAdded = false;\n",
    "        try {\n",
    "            wasAdded = set.add(o);\n",
    "            return wasAdded;\n",
    "        } finally {\n",
    "            if (!wasAdded)\n",
    "                sem.release();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public boolean remove(Object o) {\n",
    "        boolean wasRemoved = set.remove(o);\n",
    "        if (wasRemoved)\n",
    "            sem.release();\n",
    "        return wasRemoved;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Barriers\n",
    "Barriers are similar to latches in that they block a group of threads until some event has occurred. The key difference is that with a barrier, all the threads must come together at a barrier point at the same time in order to proceed. Latches are for waiting for events; barriers are for waiting for other threads.\n",
    "\n",
    "CyclicBarrier allows a fixed number of parties to rendezvous repeatedly at a barrier point and is useful in parallel iterative algorithms that break down a problem into a fixed number of independent subproblems. Threads call await when they reach the barrier point, and await blocks until all the threads have reached the barrier point. If all threads meet at the barrier point, the barrier has been successfully passed, in which case all threads are released and the barrier is reset so it can be used again. If a call to await times out or a thread blocked in await is interrupted, then the barrier is considered broken and all outstanding calls to await terminate with BrokenBarrierException. If the barrier is successfully passed, await returns a unique arrival index for each thread, which can be used to “elect” a leader that takes some special action in the next iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Building an efficient,scalable result cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like many other frequently reinvented wheels, caching often looks simpler\n",
    "than it is. A naive cache implementation is likely to turn a performance bottleneck into a scalability bottleneck, even if it does improve single-threaded performance. In this section we develop an efficient and scalable result cache for a compu- tationally expensive function. Let’s start with the obvious approach—a simple HashMap—and then look at some of its concurrency disadvantages and how to fix them.\n",
    "\n",
    "Memoizer1 in Listing shows a first attempt: using a HashMap to store the results of previous computations. The compute method first checks whether the desired result is already cached, and returns the precomputed value if it is. Otherwise, the result is computed and cached in the HashMap before returning.\n",
    "HashMap is not thread-safe, so to ensure that two threads do not access the HashMap at the same time, Memoizer1 takes the conservative approach of synchro- nizing the entire compute method. This ensures thread safety but has an obvious scalability problem: only one thread at a time can execute compute at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface Computable <A, V> {\n",
    "    V compute(A arg) throws InterruptedException;\n",
    "}\n",
    "\n",
    "class ExpensiveFunction\n",
    "        implements Computable<String, BigInteger> {\n",
    "    public BigInteger compute(String arg) {\n",
    "        // after deep thought...\n",
    "        return new BigInteger(arg);\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * Memoizer1\n",
    " *\n",
    " * Initial cache attempt using HashMap and synchronization\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class Memoizer1 <A, V> implements Computable<A, V> {\n",
    "    @GuardedBy(\"this\") private final Map<A, V> cache = new HashMap<A, V>();\n",
    "    private final Computable<A, V> c;\n",
    "\n",
    "    public Memoizer1(Computable<A, V> c) {\n",
    "        this.c = c;\n",
    "    }\n",
    "\n",
    "    public synchronized V compute(A arg) throws InterruptedException {\n",
    "        V result = cache.get(arg);\n",
    "        if (result == null) {\n",
    "            result = c.compute(arg);\n",
    "            cache.put(arg, result);\n",
    "        }\n",
    "        return result;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memoizer2 in Listing improves on the awful concurrent behavior of Memoizer1 by replacing the HashMap with a ConcurrentHashMap. Since Concur- rentHashMap is thread-safe, there is no need to synchronize when accessing the backing Map, thus eliminating the serialization induced by synchronizing compute in Memoizer1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Memoizer2\n",
    " * <p/>\n",
    " * Replacing HashMap with ConcurrentHashMap\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class Memoizer2 <A, V> implements Computable<A, V> {\n",
    "    private final Map<A, V> cache = new ConcurrentHashMap<A, V>();\n",
    "    private final Computable<A, V> c;\n",
    "\n",
    "    public Memoizer2(Computable<A, V> c) {\n",
    "        this.c = c;\n",
    "    }\n",
    "\n",
    "    public V compute(A arg) throws InterruptedException {\n",
    "        V result = cache.get(arg);\n",
    "        if (result == null) {\n",
    "            result = c.compute(arg);\n",
    "            cache.put(arg, result);\n",
    "        }\n",
    "        return result;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it still has some defects as a cache— there is a window of vulnerability in which two threads calling compute at the same time could end up computing the same value. In the case of memoization, this is merely inefficient—the purpose of a cache is to prevent the same data from being calculated multiple times. For a more general-purpose caching mechanism, it is far worse; for an object cache that is supposed to provide once-and-only-once initialization, this vulnerability would also pose a safety risk.\n",
    "\n",
    "The problem with Memoizer2 is that if one thread starts an expensive com- putation, other threads are not aware that the computation is in progress and so may start the same computation.\n",
    "\n",
    "We’d like to somehow represent the notion that “thread X is currently computing f (27)”, so that if another thread arrives looking for f (27), it knows that the most efficient way to find it is to head over to Thread X’s house, hang out there until X is finished, andthen ask “Hey, what did you get for f (27)?”\n",
    "\n",
    "FutureTask.get returns the result of the computation immediately if it is available; otherwise it blocks until the result has been computed and then returns it.\n",
    "\n",
    "Memoizer3 first checks to see if the appropriate calculation has been started (as opposed to finished, as in Memoizer2). If not, it creates a FutureTask, registers it in the Map, and starts the computation; otherwise it waits for the result of the ex- isting computation. The result might be available immediately or might be in the process of being computed—but this is transparent to the caller of Future.get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Memoizer3\n",
    " * <p/>\n",
    " * Memoizing wrapper using FutureTask\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class Memoizer3 <A, V> implements Computable<A, V> {\n",
    "    private final Map<A, Future<V>> cache\n",
    "            = new ConcurrentHashMap<A, Future<V>>();\n",
    "    private final Computable<A, V> c;\n",
    "\n",
    "    public Memoizer3(Computable<A, V> c) {\n",
    "        this.c = c;\n",
    "    }\n",
    "\n",
    "    public V compute(final A arg) throws InterruptedException {\n",
    "        Future<V> f = cache.get(arg);\n",
    "        if (f == null) {\n",
    "            Callable<V> eval = new Callable<V>() {\n",
    "                public V call() throws InterruptedException {\n",
    "                    return c.compute(arg);\n",
    "                }\n",
    "            };\n",
    "            FutureTask<V> ft = new FutureTask<V>(eval);\n",
    "            f = ft;\n",
    "            cache.put(arg, ft);\n",
    "            ft.run(); // call to c.compute happens here\n",
    "        }\n",
    "        try {\n",
    "            return f.get();\n",
    "        } catch (ExecutionException e) {\n",
    "            throw LaunderThrowable.launderThrowable(e.getCause());\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has only one defect—there is still a small window of vulnerability in which two threads might compute the same value. This window is far smaller than in Memoizer2, but because the if block in compute is still a nonatomic check-then- act sequence, it is possible for two threads to call compute with the same value at roughly the same time, both see that the cache does not contain the desired value, and both start the computation.\n",
    "\n",
    "Memoizer3 is vulnerable to this problem because a compound action (put- if-absent) is performed on the backing map that cannot be made atomic using locking. Memoizer in Listing 5.19 takes advantage of the atomic putIfAbsent method of ConcurrentMap, closing the window of vulnerability in Memoizer3.\n",
    "Caching a Future instead of a value creates the possibility of cache pollution: if a computation is cancelled or fails, future attempts to compute the result will also indicate cancellation or failure. To avoid this, Memoizer removes the Fut- ure from the cache if it detects that the computation was cancelled; it might also be desirable to remove the Future upon detecting a RuntimeException if the computation might succeed on a future attempt. \n",
    "\n",
    "Memoizer also does not address cache expiration, but this could be accomplished by using a subclass of Future- Task that associates an expiration time with each result and periodically scanning the cache for expired entries. (Similarly, it does not address cache eviction, where old entries are removed to make room for new ones so that the cache does not consume too much memory.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Memoizer\n",
    " * <p/>\n",
    " * Final implementation of Memoizer\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "public class Memoizer <A, V> implements Computable<A, V> {\n",
    "    private final ConcurrentMap<A, Future<V>> cache\n",
    "            = new ConcurrentHashMap<A, Future<V>>();\n",
    "    private final Computable<A, V> c;\n",
    "\n",
    "    public Memoizer(Computable<A, V> c) {\n",
    "        this.c = c;\n",
    "    }\n",
    "\n",
    "    public V compute(final A arg) throws InterruptedException {\n",
    "        while (true) {\n",
    "            Future<V> f = cache.get(arg);\n",
    "            if (f == null) {\n",
    "                Callable<V> eval = new Callable<V>() {\n",
    "                    public V call() throws InterruptedException {\n",
    "                        return c.compute(arg);\n",
    "                    }\n",
    "                };\n",
    "                FutureTask<V> ft = new FutureTask<V>(eval);\n",
    "                f = cache.putIfAbsent(arg, ft);\n",
    "                if (f == null) {\n",
    "                    f = ft;\n",
    "                    ft.run();\n",
    "                }\n",
    "            }\n",
    "            try {\n",
    "                return f.get();\n",
    "            } catch (CancellationException e) {\n",
    "                cache.remove(arg, f);\n",
    "            } catch (ExecutionException e) {\n",
    "                throw LaunderThrowable.launderThrowable(e.getCause());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>javax.servlet</groupId>\n",
    "    <artifactId>javax.servlet-api</artifactId>\n",
    "    <version>3.1.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Documented\n",
    "@Target(ElementType.TYPE)\n",
    "@Retention(RetentionPolicy.RUNTIME)\n",
    "public @interface ThreadSafe {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.math.BigInteger;\n",
    "import javax.servlet.*;\n",
    "/**\n",
    " * Factorizer\n",
    " * <p/>\n",
    " * Factorizing servlet that caches results using Memoizer\n",
    " *\n",
    " * @author Brian Goetz and Tim Peierls\n",
    " */\n",
    "@ThreadSafe\n",
    "public class Factorizer extends GenericServlet implements Servlet {\n",
    "    private final Computable<BigInteger, BigInteger[]> c =\n",
    "            new Computable<BigInteger, BigInteger[]>() {\n",
    "                public BigInteger[] compute(BigInteger arg) {\n",
    "                    return factor(arg);\n",
    "                }\n",
    "            };\n",
    "    private final Computable<BigInteger, BigInteger[]> cache\n",
    "            = new Memoizer<BigInteger, BigInteger[]>(c);\n",
    "\n",
    "    public void service(ServletRequest req,\n",
    "                        ServletResponse resp) {\n",
    "        try {\n",
    "            BigInteger i = extractFromRequest(req);\n",
    "            encodeIntoResponse(resp, cache.compute(i));\n",
    "        } catch (InterruptedException e) {\n",
    "            encodeError(resp, \"factorization interrupted\");\n",
    "        }\n",
    "    }\n",
    "\n",
    "    void encodeIntoResponse(ServletResponse resp, BigInteger[] factors) {\n",
    "    }\n",
    "\n",
    "    void encodeError(ServletResponse resp, String errorString) {\n",
    "    }\n",
    "\n",
    "    BigInteger extractFromRequest(ServletRequest req) {\n",
    "        return new BigInteger(\"7\");\n",
    "    }\n",
    "\n",
    "    BigInteger[] factor(BigInteger i) {\n",
    "        // Doesn't really factor\n",
    "        return new BigInteger[]{i};\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Part I\n",
    "We’ve covered a lot of material so far! The following “concurrency cheat sheet” summarizes the main concepts and rules presented in Part I.\n",
    "* It’s the mutable state, stupid.1\n",
    "    * All concurrency issues boil down to coordinating access to mutable state. The less mutable state, the easier it is to ensure thread safety.\n",
    "* Make fields final unless they need to be mutable.\n",
    "* Immutable objects are automatically thread-safe.\n",
    "    * Immutable objects simplify concurrent programming tremendously. They are simpler and safer, and can be shared freely without locking or defensive copying.\n",
    "* Encapsulation makes it practical to manage the complexity.\n",
    "    * You could write a thread-safe program with all data stored in global variables, but why would you want to? Encapsulating data within objects makes it easier to preserve their invariants; encapsulating synchronization within objects makes it easier to comply with their synchronization policy.\n",
    "* Guard each mutable variable with a lock.\n",
    "* Guard all variables in an invariant with the same lock.\n",
    "* Hold locks for the duration of compound actions.\n",
    "* A program that accesses a mutable variable from multiple threads without synchronization is a broken program.\n",
    "* Don’t rely on clever reasoning about why you don’t need to synchro- nize.\n",
    "* Include thread safety in the design process—or explicitly document that your class is not thread-safe.\n",
    "* Document your synchronization policy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "14.0.1+7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
